<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>SlaBins</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://Syniez.github.io/SlaBins/SlaBins_teasure.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://Syniez.github.io/SlaBins" />
    <meta property="og:title" content="[ICCV 2023] SlaBins" />
    <meta property="og:description" content="Fisheye Depth Estimation using Slanted Bins on the Road Environments" />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="[ICCV 2023] SlaBins" />
    <meta name="twitter:description" content="Fisheye Depth Estimation using Slanted Bins on the Road Environments" />
    <meta name="twitter:image" content="https://Syniez.github.io/SlaBins/SlaBins_teasure.png" />

    <script>
      window.dataLayer = window.dataLayer || [];
      
      function gtag() {
      dataLayer.push(arguments);
      }

      gtag('js', new Date());

      gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/font-awesome-4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" type="text/css" href="./static/css/magnifier.css">
    
    <!-- BootStrap4 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
        integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
        integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js"
        integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js"
        integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
        crossorigin="anonymous"></script>

    <!-- Material Icons -->
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
</head>

<body>
    <div class="container" id="main">

        <!-- Top padding -->
        <div class="row mt-md-5"></div>

        <div class="row">
            <h2 class="col text-center">
                <b>SlaBins:</b> Fisheye Depth Estimation using Slanted Bins on the Road Environments
                <br><br>
                <span class="realistic-marker-highlight">ICCV 2023</span>

                <svg xmlns="//www.w3.org/2000/svg" version="1.1" class="svg-filters" style="display:none;">
                    <defs>
                        <filter id="marker-shape">
                            <feTurbulence type="fractalNoise" baseFrequency="0 0.15" numOctaves="1" result="warp" />
                            <feDisplacementMap xChannelSelector="R" yChannelSelector="G" scale="30" in="SourceGraphic"
                                in2="warp" />
                        </filter>
                    </defs>
                </svg>
            </h2>
        </div>


        <div class="row mt-3">
            <div class="col-md-2"></div>
            <div class="col text-center">
                <a href="https://github.com/Syniez">
                    Jongsung Lee
                </a><sup>1</sup>
            </div>
            <div >
                <a href="https://github.com/Threedv">
                    Gyeongsu Cho
                </a><sup>1, *</sup>
            </div>
            <div class="col text-center">
                <a href="https://github.com/Jeongin-park">
                    Jeongin Park
                </a><sup>1, *</sup>
            </div>
            <div class="col text-center">
                <a href="https://github.com/kimkj38">
                    Kyongjun Kim
                </a><sup>1, *</sup>
            </div>
            <div class="col text-center">
                <a href="https://github.com/solee7650">
                    Seongoh Lee
                </a><sup>1, *</sup>
            </div>
            <div class="col-md-2"></div>
        </div>
        <div class="row mt-3">
            <div class="col-md-2"></div>
                <div class="col text-center">
                    <a href="#">
                        Junghee Kim
                    </a><sup>2</sup>
                </div>
                <div class="col text-center">
                    <a href="#">
                        seonggyun Jung
                    </a><sup>2</sup>
                </div>
                <div class="col text-center">
                    <a href="http://rvi.unist.info">
                        Kyungdon Joo
                    </a><sup>1</sup>
                </div>
            <div class="col-md-2"></div>
        </div>

        <br>
        <div class="col text-center">
            <span><sup>1</sup> Ulsan National Institute of Science & Technology &nbsp;&nbsp;</span>
        </div>
        <div class="col text-center">
            <span><sup>2</sup> 42dot Inc &nbsp;&nbsp;</span>
        </div>
        <div class="col text-center">
            <span><sup>*</sup> Equal contribution &nbsp;&nbsp;</span>
        </div>

        <div class="row justify-content-center align-items-center mt-3">
            <div class="col-md-3"></div>
            <div class="col text-center">
                <a href="#">
                    <h4>
                        <span class="material-icons">description</span><br>
                        <strong>Paper</strong>
                    </h4>
                    (Coming soon)
                </a>
            </div>
            <div class="col text-center">
                <a href="#">
                    <h4>
                        <span class="material-icons">code</span><br>
                        <strong>Code</strong>
                    </h4>
                    (Coming Soon)
                </a>
            </div>
            <div class="col text-center">
                <a href="#">
                    <h4>
                        <span class="material-icons">folder</span><br>
                        <strong>Dataset</strong>
                    </h4>
                    (Coming Soon)
                </a>
            </div>
            <div class="col-md-3"></div>
        </div>


        <div class="row mt-5">
            <div class="col">
                <h3><i>Abstract</i></h3>
                <p class="text-justify">
                    Although 3D perception for autonomous vehicles has focused on frontal-view information, more than half of fatal accidents occur due to side impacts in practice (<i>e.g.,</i> T-bone crash).
                    Motivated by this fact, we investigate the problem of side-view depth estimation, especially for monocular fisheye cameras, which provide wide FoV information.
                    However, since fisheye cameras head road areas, it observes road areas mostly and results in severe distortion on object areas, such as vehicles or pedestrians.
                    To alleviate these issues, we propose a new fisheye depth estimation network, SlaBins, that infers an accurate and dense depth map based on a geometric property of road environments; most objects are standing (<i>i.e.,</i> orthogonal) on the road environments.
                    Concretely, we introduce a slanted multi-cylindrical image (MCI) representation, which allows us to describe a distance as a radius to a cylindrical layer orthogonal to the ground regardless of the camera viewing direction.
                    Based on the slanted MCI, we estimate a set of adaptive bins and a per-pixel probability map for depth estimation.
                    Then by combining it with the estimated slanted angle of viewing direction, we directly infer a dense and accurate depth map for fisheye cameras.
                    Experiments demonstrate that <i><b>SlaBins</b></i> outperforms the state-of-the-art methods in both qualitative and quantitative evaluation on the SynWoodScape and KITTI-360 depth datasets.
                </p>
            </div>
        </div>


        <div class="row mt-5">
            <div class="col">
                <img src="./imgs/SlaBins_teaser.png" width="100%">
            </div>
        </div>
        <div class="row">
            <div class="col">
                <!-- <p class="text-center">
                    Generated human bodies in different test scenes of the <em>PROX dataset</em>.
                    Each row represents generated 3D human avatars in a given scene.
                </p> -->
            </div>
        </div>


        <div class="row">
            <div class="col">
                <h3><i>Methodology</i></h3>
                <div class="text-center">
                    <p class="text-justify">
                        Inspired by the geometric property of the road environments, we propose a new fisheye depth estimation framework.
                        Specifically, we introduce a slanted MCI representation, which allows us to describe a multi-layer cylindrical image orthogonal to the road ground regardless of the viewing direction of the camera.
                        Based on the slanted MCI representation, our SlaBins module estimates the adaptive bin widths and per-pixel probability map in the orthogonal coordinate, which provides depth information invariant to the camera viewing direction.
                        We then combine the estimated depth information with the slanted angle estimated by the slanted angle prediction module.
                        Through this process, we can directly estimate a dense depth map for fisheye cameras.     
                    </p>
                </div>
            </div>
        </div>


        <!-- Depth Estimation Results -->
        <div class="row mt-5">
            <div class="col">
                <h3><i>Depth Estimation Results</i></h3>
                <p class="text-justify">
                    Estimated depth results on <b>SynWoodScape</b> and <b>KITTI-360</b> dataset.
                </p>
            </div>
        </div>
        <div class="row mt-5">
            <div class="col">
                <img src="./imgs/SynWood_results.png" width="100%">
            </div>
        </div>
        <div class="row">
            <div class="col">
            </div>
        </div>
        <div class="row mt-5">
            <div class="col">
                <img src="./imgs/Kitti_results.png" width="100%">
            </div>
        </div>
        <div class="row">
            <div class="col">
            </div>
        </div>


        <!-- Qualitative comparison with other methods -->
        <div class="row mt-5">
            <div class="col">
                <h3><i>Qualitative Comparison</i></h3>
            </div>
        </div>

    <section>
      <div class="container"> 
          <div class="column is-full-width">
              <!-- Images -->
              <div class="img-zoom-container" align="center">
                <figure display="inline-block">
                  <img id="reference"
                       src="imgs/SlaBins_teaser.png" data-image="imgs/" >
                  <figcaption>Reference</figcaption>
                </figure>
                
                <figure display="inline-block">
                  <div id="zoomed-imap" class="img-zoom-result"
                       data-image="imgs/"></div>
                  <figcaption><a href="https://edgarsucar.github.io/iMAP/">iMAP<sup>*</sup></a></figcaption>
                </figure>
                
                <figure display="inline-block">
                  <div id="zoomed-nice" class="img-zoom-result"
                       data-image="imgs/"></div>
                  <figcaption><a href="https://pengsongyou.github.io/nice-slam">NICE-SLAM</a></figcaption>
                </figure>
                
                <figure display="inline-block">
                  <div id="zoomed-eslam" class="img-zoom-result"
                       data-image="imgs/"></div>
                  <figcaption>ESLAM (Ours)</figcaption>
                </figure>

              </div>
              <br>
              <figcaption style="font-size: small">&nbsp &nbsp iMAP<sup>*</sup> is the reimplementation of <a href="https://edgarsucar.github.io/iMAP/">iMAP</a> by <a href="https://pengsongyou.github.io/nice-slam">NICE-SLAM.</a></figcaption>
        </div>
      </div>
    </section>
                



        <div class="row mt-5">
            <div class="col col-md-offset-2">
                <h3><i>Acknowledgements</i></h3>
                <p class="text-justify">
                    This work was supported by Institute of Information & communications Technology Planning &
                    Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2022-0-00612, Geometric and
                    Physical Commonsense Reasoning based Behavior Intelligence for Embodied AI, No.2022-0-00907,
                    Development of AI Bots Collaboration Platform and Self-organizing AI and No.2020-0-01336, Artificial
                    Intelligence Graduate School Program (UNIST)) and Artificial intelligence industrial convergence
                    cluster development project funded by the Ministry of Science and ICT (MSIT, Korea) & Gwangju
                    Metropolitan City.
                </p>
            </div>
        </div>
    </div>


    <footer class="text-center text-lg-start bg-white text-muted mt-5">
        <div class="text-center p-4" style="background-color: rgba(0, 0, 0, 0.025);">
            The website template was borrowed from
            <a href="https://kitsunetic.github.io">Jaehyeok Shim</a>.
        </div>
    </footer>


</body>

</html>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="./static/js/bulma-carousel.min.js"></script>
<script src="./static/js/bulma-slider.min.js"></script>
<script src="./static/js/index.js"></script>  

<script src="./static/js/magnifier.js"></script>
<script> imageZoom("reference", ["zoomed-imap", "zoomed-nice", "zoomed-eslam" ], 7); </script>
