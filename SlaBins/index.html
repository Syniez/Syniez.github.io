<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>SlaBins</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://Syniez.github.io/SlaBins/SlaBins_teasure.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://Syniez.github.io/SlaBins" />
    <meta property="og:title" content="[ICCV 2023] SlaBins" />
    <meta property="og:description" content="Fisheye Depth Estimation using Slanted Bins on the Road Environments" />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="[ICCV 2023] SlaBins" />
    <meta name="twitter:description" content="Fisheye Depth Estimation using Slanted Bins on the Road Environments" />
    <meta name="twitter:image" content="https://Syniez.github.io/SlaBins/SlaBins_teasure.png" />

    <!-- BootStrap4 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
        integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
        integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js"
        integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js"
        integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
        crossorigin="anonymous"></script>

    <!-- Material Icons -->
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
</head>

<body>
    <div class="container" id="main">

        <!-- Top padding -->
        <div class="row mt-md-5"></div>

        <div class="row">
            <h2 class="col text-center">
                <b>SlaBins: Fisheye Depth Estimation using Slanted Bins on the Road Environments
                <br><br>
                <span class="realistic-marker-highlight">ICCV 2023</span>

                <svg xmlns="//www.w3.org/2000/svg" version="1.1" class="svg-filters" style="display:none;">
                    <defs>
                        <filter id="marker-shape">
                            <feTurbulence type="fractalNoise" baseFrequency="0 0.15" numOctaves="1" result="warp" />
                            <feDisplacementMap xChannelSelector="R" yChannelSelector="G" scale="30" in="SourceGraphic"
                                in2="warp" />
                        </filter>
                    </defs>
                </svg>
            </h2>
        </div>


        <div class="row mt-3">
            <div class="col-md-2"></div>
            <div class="col text-center">
                <a href="https://kitsunetic.github.io/">
                    Jongsung Lee
                </a>
            </div>
            <div class="col text-center">
                <a href="https://github.com/Kang-ChangWoo">
                    Gyeongsu Cho
                </a>
            </div>
            <div class="col text-center">
                <a href="http://rvi.unist.info">
                    Jeongin Park
                </a>
            </div>
            <div class="col text-center">
                <a href="http://rvi.unist.info">
                    Kyongjun Kim
                </a>
            </div>
            <div class="col text-center">
                <a href="http://rvi.unist.info">
                    Seongoh Lee
                </a>
            </div>
            <div class="col text-center">
                <a href="http://rvi.unist.info">
                    Kyungdon Joo
                </a>
            </div>
            <div class="col-md-2"></div>
        </div>
        <div class="row text-center mt-2">
            <div class="col-12">
                UNIST
            </div>
        </div>


        <div class="row justify-content-center align-items-center mt-3">
            <div class="col-md-3"></div>
            <div class="col text-center">
                <a href="#">
                    <h4>
                        <span class="material-icons">description</span><br>
                        <strong>Paper</strong>
                    </h4>
                    (Coming soon)
                </a>
            </div>
            <div class="col text-center">
                <a href="#">
                    <h4>
                        <span class="material-icons">code</span><br>
                        <strong>Code</strong>
                    </h4>
                    (Coming Soon)
                </a>
            </div>
            <div class="col-md-3"></div>
        </div>


        <div class="row mt-5">
            <div class="col">
                <img src="./imgs/SlaBins_teaser.png" width="100%">
            </div>
        </div>
        <div class="row">
            <div class="col">
                <!-- <p class="text-center">
                    Generated human bodies in different test scenes of the <em>PROX dataset</em>.
                    Each row represents generated 3D human avatars in a given scene.
                </p> -->
            </div>
        </div>


        <div class="row mt-5">
            <div class="col">
                <h3><i>Abstract</i></h3>
                <p class="text-justify">
                    Although 3D perception for autonomous vehicles has focused on frontal-view information, more than half of fatal accidents occur due to side impacts in practice (\eg T-bone crash).
                    Motivated by this fact, we investigate the problem of side-view depth estimation, especially for monocular fisheye cameras, which provide wide FoV information.
                    However, since fisheye cameras head road areas, it observes road areas mostly and results in severe distortion on object areas, such as vehicles or pedestrians.
                    To alleviate these issues, we propose a new fisheye depth estimation network, SlaBins, that infers an accurate and dense depth map based on a geometric property of road environments; most objects are standing (\ie orthogonal) on the road environments.
                    Concretely, we introduce a slanted multi-cylindrical image (MCI) representation, which allows us to describe a distance as a radius to a cylindrical layer orthogonal to the ground regardless of the camera viewing direction.
                    Based on the slanted MCI, we estimate a set of adaptive bins and a per-pixel probability map for depth estimation.
                    Then by combining it with the estimated slanted angle of viewing direction, we directly infer a dense and accurate depth map for fisheye cameras.
                    Experiments demonstrate that SlaBins outperforms the state-of-the-art methods in both qualitative and quantitative evaluation on the SynWoodScape and KITTI-360 depth datasets.
                </p>
            </div>
        </div>


        <div class="row mt-5">
            <div class="col embed-responsive embed-responsive-16by9">
                <!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/96DqsvY09X4" title="CVPR Video" -->
                <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/96DqsvY09X4" title="CVPR Video"
                    frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                    allowfullscreen></iframe>
            </div>
        </div>


        <div class="row mt-5">
            <div class="col-md-2"></div>
            <div class="col text-center">
                <img src="./img/method.png" width="100%">
            </div>
            <div class="col-md-2"></div>
        </div>
        <div class="row">
            <div class="col">
                <h3><i>Methodology</i></h3>
                <div class="text-center">
                    <p class="text-justify">
                        An overview of our method.
                        Our method can generate high-resolution 3D shapes in the form of SDF voxels based on the
                        denoising diffusion model (DDM).
                        Our method has two stages: low-resolution coarse shape generation (top of the figure) and shape
                        super-resolution for high-resolution fine shape on the voxel-shaped SDF (bottom of the figure).
                        In the first stage, a diffusion-based 3d generative model learns to create realistic
                        low-resolution 3D shapes.
                        In the second stage, a diffusion-based super-resolution model is trained to upsample the 3D
                        shapes.
                        To alleviate cubic memory issue to handle high-resolution voxel, the second stage model is
                        trained to super-resolve 3D shapes from corresponding high- and low-resolution patches.
                    </p>
                </div>
            </div>
        </div>


        <!-- Generation Results -->
        <div class="row mt-5">
            <div class="col">
                <h3><i>Generation Results</i></h3>
                <p class="text-justify">
                    Generated 3D shapes from our method trained on ShapeNet dataset.
                    32, 64, 128 means resolution of voxel-shaped SDF of generated samples.
                </p>
            </div>
        </div>


        <!-- <div class="row mt-2">
            <div class="col-md-2"></div>
            <div class="col">
                <img src="./img/1.png" width="100%">
            </div>
            <div class="col-md-2"></div>
        </div> -->
        <!-- <div class="row mt-2">
            <div class="col-md-2"></div>
            <div class="col">
                <img src="./img/2.png" width="100%">
            </div>
            <div class="col-md-2"></div>
        </div> -->
        <!-- <div class="row mt-2">
            <div class="col-md-2"></div>
            <div class="col">
                <img src="./img/3.png" width="100%">
            </div>
            <div class="col-md-2"></div>
        </div> -->


        <!-- Additional slider style -->
        <style>
            .carousel-control-prev-icon,
            .carousel-control-next-icon {
                height: 100px;
                width: 100px;
                outline: rgb(20, 20, 200);
                background-size: 100%, 100%;
                border-radius: 50%;
                /* border: 1px solid black; */
                background-image: none;
            }

            .carousel-control-next-icon:after {
                content: '>';
                font-size: 55px;
                color: rgb(20, 20, 200);
            }

            .carousel-control-prev-icon:after {
                content: '<';
                font-size: 55px;
                color: rgb(20, 20, 200);
            }

            carousel-indicators {
                position: absolute;
                right: 0;
                bottom: 10px;
                left: 0;
                z-index: 15;
                display: -webkit-box;
                display: -ms-flexbox;
                display: flex;
                -webkit-box-pack: center;
                -ms-flex-pack: center;
                justify-content: center;
                padding-left: 0;
                margin-right: 15%;
                margin-left: 15%;
                list-style: none
            }

            .carousel-indicators li {
                position: relative;
                -webkit-box-flex: 0;
                -ms-flex: 0 1 auto;
                flex: 0 1 auto;
                width: 30px;
                height: 3px;
                margin-right: 3px;
                margin-left: 3px;
                text-indent: -999px;
                background-color: rgba(200, 200, 200, .5)
            }

            .carousel-indicators li::before {
                position: absolute;
                top: -10px;
                left: 0;
                display: inline-block;
                width: 100%;
                height: 10px;
                content: ""
            }

            .carousel-indicators li::after {
                position: absolute;
                bottom: -10px;
                left: 0;
                display: inline-block;
                width: 100%;
                height: 10px;
                content: ""
            }

            .carousel-indicators .active {
                background-color: rgb(20, 20, 200)
            }

        </style>
        <div class="row mt-2">
            <div class="col-md-2"></div>
            <div class="col">
                <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel">
                    <ol class="carousel-indicators">
                        <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
                        <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
                        <li data-target="#carouselExampleIndicators" data-slide-to="2"></li>
                    </ol>
                    <div class="carousel-inner">
                        <div class="carousel-item active">
                            <img class="d-block w-100" src="./img/1.png" alt="First slide">
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="./img/2.png" alt="Second slide">
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="./img/3.png" alt="Third slide">
                        </div>
                    </div>
                    <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
                        <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                        <span class="sr-only">Previous</span>
                    </a>
                    <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
                        <span class="carousel-control-next-icon" aria-hidden="true"></span>
                        <span class="sr-only">Next</span>
                    </a>
                </div>
            </div>
            <div class="col-md-2"></div>
        </div>


        <!-- Completion Results -->
        <div class="row mt-5">
            <div class="col">
                <h3><i>Shape Completion Results</i></h3>
                <p class="text-justify">
                    Our method is capable of generating 3D shapes with conditioned on partial 3D shapes.
                    Using the same condition input, our method can produce various harmonious candidates.
                </p>
            </div>
        </div>
        <div class="row mt-2">
            <div class="col-md-2"></div>
            <div class="col">
                <img src="./img/completion.png" width="100%">
            </div>
            <div class="col-md-2"></div>
        </div>


        <div class="row mt-5">
            <div class="col col-md-offset-2">
                <h3><i>Acknowledgements</i></h3>
                <p class="text-justify">
                    This work was supported by Institute of Information & communications Technology Planning &
                    Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2022-0-00612, Geometric and
                    Physical Commonsense Reasoning based Behavior Intelligence for Embodied AI, No.2022-0-00907,
                    Development of AI Bots Collaboration Platform and Self-organizing AI and No.2020-0-01336, Artificial
                    Intelligence Graduate School Program (UNIST)) and Artificial intelligence industrial convergence
                    cluster development project funded by the Ministry of Science and ICT (MSIT, Korea) & Gwangju
                    Metropolitan City.
                </p>
            </div>
        </div>
    </div>


    <footer class="text-center text-lg-start bg-white text-muted mt-5">
        <div class="text-center p-4" style="background-color: rgba(0, 0, 0, 0.025);">
            The website template was borrowed from
            <a href="https://kitsunetic.github.io">Jaehyeok Shim</a>.
        </div>
    </footer>


</body>

</html>
